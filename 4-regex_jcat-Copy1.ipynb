{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on Introduction to `regex`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we'll learn about a useful tool in the NLP toolkit: regex.\n",
    "\n",
    "Let's consider two motivating examples:\n",
    "\n",
    "#### 1. The phone number problem\n",
    "\n",
    "Suppose we are given some data that includes phone numbers:\n",
    "\n",
    "123-456-7890\n",
    "\n",
    "123 456 7890\n",
    "\n",
    "101 Howard\n",
    "\n",
    "Some of the phone numbers have different formats (hyphens, no hyphens).  Also, there are some errors in the data-- 101 Howard isn't a phon number!  How can we find all the phone numbers?\n",
    "\n",
    "#### 2. Creating our own tokens\n",
    "\n",
    "In the previous lessons, we used sklearn or fastai to tokenize our text.  What if we want to do it ourselves?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The phone number problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we are given some data that includes phone numbers:\n",
    "\n",
    "123-456-7890\n",
    "\n",
    "123 456 7890\n",
    "\n",
    "(123)456-7890\n",
    "\n",
    "101 Howard\n",
    "\n",
    "Some of the phone numbers have different formats (hyphens, no hyphens, parentheses).  Also, there are some errors in the data-- 101 Howard isn't a phone number!  How can we find all the phone numbers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will attempt this without regex, but will see that this quickly leads to lot of if/else branching statements and isn't a veyr promising approach:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without `regex`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.text import *\n",
    "from fastai.utils.mem import GPUMemTrace #call with mtrace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here are some example strings. We would like to write a function to decide whether or not they are valid phone numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone1 = \"123-456-7890\"\n",
    "\n",
    "phone2 = \"123 456 7890\"\n",
    "\n",
    "not_phone1 = \"101 Howard\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0123456789'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check that the string only contains digits, or the characters -, (, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_phone(inp):\n",
    "    valid_chars = string.digits + ' -()'\n",
    "    for char in inp:\n",
    "        if char not in valid_chars:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(check_phone(phone1))\n",
    "assert(check_phone(phone2))\n",
    "assert(not check_phone(not_phone1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So far so good. But this test string 'breaks' our code:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_phone2 = \"1234\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-b9be6285b0d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mcheck_phone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnot_phone2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# check_phone(not_phone2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert(not check_phone(not_phone2))\n",
    "# check_phone(not_phone2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ok, let's improve our function to handle this edge case: we'll make sure the string has exactly 10 digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_phone(inp):\n",
    "    nums = string.digits\n",
    "    valid_chars = nums + ' -()'\n",
    "    num_counter = 0\n",
    "    for char in inp:\n",
    "        if char not in valid_chars:\n",
    "            return False\n",
    "        if char in nums:\n",
    "            num_counter += 1\n",
    "    if num_counter==10:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(check_phone(phone1))\n",
    "assert(check_phone(phone2))\n",
    "assert(not check_phone(not_phone1))\n",
    "assert(not check_phone(not_phone2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### But what about these examples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is correctly rejected\n",
    "not_phone3 = '34!NA5098gn#213ee2'\n",
    "assert(not check_phone(not_phone3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-364-80c7268f2725>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnot_phone4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"34 50 98 21 32\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mcheck_phone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnot_phone4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# This is not rejected\n",
    "not_phone4 = \"34 50 98 21 32\"\n",
    "assert(not check_phone(not_phone4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-366-d0961ddf5078>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# This is not rejected\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mnot_phone5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"(34)(50)()()982132\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mcheck_phone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnot_phone4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# This is not rejected\n",
    "not_phone5 = \"(34)(50)()()982132\"\n",
    "assert(not check_phone(not_phone4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is getting increasingly unwieldy.  We need a different approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Introducing `regex`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful regex resources:\n",
    "\n",
    "- https://regexr.com/\n",
    "- http://callumacrae.github.io/regex-tuesday/\n",
    "- https://regexone.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best practice: Be as specific as possible.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parts of the following section were adapted from Brian Spiering, who taught the MSDS [NLP elective last summer](https://github.com/brianspiering/nlp-course)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What is regex?\n",
    "\n",
    "Regular expressions is a pattern matching language. \n",
    "\n",
    "Instead of writing `0 1 2 3 4 5 6 7 8 9`, you can write `[0-9]` or `\\d`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It is Domain Specific Language (DSL). Powerful (but limited language). \n",
    "\n",
    "**What other DSLs do you already know?**\n",
    "- SQL  \n",
    "- Markdown\n",
    "- TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Matching Phone Numbers (The \"Hello, world!\" of Regex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`[0-9][0-9][0-9]-[0-9][0-9][0-9]-[0-9][0-9][0-9][0-9]` matches US telephone number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Refactored: `\\d\\d\\d-\\d\\d\\d-\\d\\d\\d\\d`\n",
    "\n",
    "A **metacharacter** is one or more special characters that have a unique meaning and are NOT used as literals in the search expression. For example \"\\d\" means any digit.\n",
    "\n",
    "**Metacharacters are the special sauce of regex.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Quantifiers\n",
    "-----\n",
    "\n",
    "Allow you to specify how many times the preceding expression should match. \n",
    "\n",
    "`{}` is an exact qualifer\n",
    "\n",
    "Refactored: `\\d{3}-\\d{3}-\\d{4}`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Unexact quantifiers\n",
    "\n",
    "1. `?` question mark - zero or one \n",
    "2. `*` star - zero or more\n",
    "3. `+` plus sign - one or more | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regex can look really weird, since it's so concise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best (only?) way to learn it is through practice.  Otherwise, you feel like you're just reading lists of rules.\n",
    "\n",
    "Let's take 15 minutes to begin working through the lessons on [regexone](https://regexone.com/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reminder: Be as specific as possible!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pros & Cons of Regex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**What are the advantages of regex?**\n",
    "\n",
    "1. Concise and powerful pattern matching DSL\n",
    "2. Supported by many computer languages, including SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**What are the disadvantages of regex?**\n",
    "\n",
    "1. Brittle \n",
    "2. Hard to write, can get complex to be correct\n",
    "3. Hard to read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary of regex metacharacters\n",
    "\n",
    "note: in the following, \"character\" can refer to a single character or a group of characters\n",
    "\n",
    "\\ make following meta-character into a literal <br>\n",
    "\\d match one instance of digit<br>\n",
    "\\D match one instance of non-digit<br>\n",
    "\\w match one instance of alphanumeric<br>\n",
    "\\W match one instance of non-alphanumeric (symbol)<br>\n",
    "\\s match one instance of whitespace<br>\n",
    "\\S match one instance of non-whitespace<br>\n",
    "\n",
    ". match one instance of any character (wildcard match)<br>\n",
    "? match 0 or 1 instance of preceding character (optional match)<br>\n",
    "\n",
    "\n",
    "\\+ match 1 or more instance of preceding character (mandatory match)<br>\n",
    "\\* match 0 or more instance of preceding character (optional match)<br>\n",
    "\n",
    "c{3} match a string which contains 3 instances of c, the preceding character<br>\n",
    "c{m,n} Match a string in which the preceding character c occurs at least m times, and at most n times.\n",
    "\n",
    "[] encloses an expression that selects exactly one instance of a character class:\n",
    "[a-z] match exactly one instance of any of the characters a through z<br>\n",
    "^ is a regex character with a split personality (there might be others)\n",
    "^ when occurring inside brackets [], ^ means \"not\", i.e. <br>\n",
    "[^a-z] match exactly one instance of a character that is not a through z<br>\n",
    "\n",
    "otherwise, ^ refers to the character at the beginning of a string: <br>\n",
    "^A match A if it is the first character in a string<br>\n",
    "\n",
    "x\\\\$ refers to the character x at the end of a string: <br>\n",
    "\\\\.\\\\$ match a period if it is the last character in a string<br>\n",
    "z\\\\$ match a z if it is the last character in a string<br>\n",
    "\\w\\\\$ match an alphanumeric if it is the last character in a string <br>\n",
    "\n",
    "(dog) match a string group containing the characters d, o, g in that order <br>\n",
    "\n",
    "<img src=\"regex.png\" alt=\"regex metacharacters\" style=\"width: 30%\"/>\n",
    "\n",
    "ref: - https://regexone.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tokenizers revisited: using regex to build our own tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous lessons, we used a tokenizer.  Now, let's learn how we could do this ourselves, and get a better understanding of tokenization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we needed to create our own tokens? <br>First we need to access `regex`, which lives in the  `re` package  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The tokenizer needs to find sequences of characters that are words or numbers, and separate out the punctuation marks, and endings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note about the code cell below: r\"*string*\" is a `python` (not `regex`) command that tells the string interpreter that the *string* enclosed between the quotes is a *raw text expression*, meaning that python's string metacharacters $^{\\dagger}$ are interpreted  as `literals` rather than being parsed with their `meta` superpowers. <br>\n",
    "$^{\\dagger}$ such as escape sequences like \\\\' and \\\\\" that also encode the \\' and \\\" characters and can be used inside a string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capture punctuation, including python escape sequences\n",
    "re_punc = re.compile(r\"([\\\"\\''().,;:/_?!‚Äî\\-])\") \n",
    "\n",
    "# capture the n't ending\n",
    "re_apos = re.compile(r\"n ' t \")\n",
    "\n",
    "#capture the 's ending\n",
    "re_bpos = re.compile(r\" ' s \")\n",
    "\n",
    "# Note that there are other word endings that we could have added, such as the\n",
    "# 'd in you'd, I'd, we'd\n",
    "# 'll in I'll you'll we'll\n",
    "\n",
    "# capture sequences of multiple blank spaces (we'll replace these with a single blank space)\n",
    "re_mult_space = re.compile(r\" +\") \n",
    "\n",
    "# Here is a function that takes as input any text string (called sent)\n",
    "#     the awkward construction is so we can access all the intermediate results\n",
    "def simple_toks(text):\n",
    "    # substitions to be made\n",
    "    text0 = re_punc.sub(\" \", text)\n",
    "    text1 = re_punc.sub(r\" \\1 \", text)\n",
    "    text2 = re_apos.sub(r\" n't \", text1)\n",
    "    text3 = re_bpos.sub(r\" 's \", text2)\n",
    "    text4 = re_mult_space.sub(' ', text3)\n",
    "    text5 = text4.lower()\n",
    "    text6 = text5.split()\n",
    "    return text0, text1, text2, text3, text4, text5, text6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's test simple_tok() to see if it properly tokenizes a sentence that includes lots of punctuation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = r\"I don't know who Kara's 10 new friend(s) are; -- is one of them 'Mr./Mrs. Toad'?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Did we get the desired output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'know',\n",
       " 'who',\n",
       " 'kara',\n",
       " \"'s\",\n",
       " '10',\n",
       " 'new',\n",
       " 'friend',\n",
       " '(',\n",
       " 's',\n",
       " ')',\n",
       " 'are',\n",
       " ';',\n",
       " '-',\n",
       " '-',\n",
       " 'is',\n",
       " 'one',\n",
       " 'of',\n",
       " 'them',\n",
       " \"'\",\n",
       " 'mr',\n",
       " '.',\n",
       " '/',\n",
       " 'mrs',\n",
       " '.',\n",
       " 'toad',\n",
       " \"'\",\n",
       " '?']"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_toks(text)[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As a final bit of pre-processing, `join` the `list` of `tokens` into a single `string`, using a  whitespace `separator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i do n't know who kara 's 10 new friend ( s ) are ; - - is one of them ' mr . / mrs . toad ' ?\""
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(simple_toks(text)[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "text0, text1, text2, text3, text4, text5, text6 = simple_toks(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I don t know who Kara s 10 new friend s  are     is one of them  Mr  Mrs  Toad  '"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in text substitute a blank character for every punctuation character\n",
    "text0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don ' t know who Kara ' s 10 new friend ( s )  are ;   -  -  is one of them  ' Mr .  / Mrs .  Toad '  ? \""
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in text, add spaces around every captured punctuation character\n",
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I do n't know who Kara ' s 10 new friend ( s )  are ;   -  -  is one of them  ' Mr .  / Mrs .  Toad '  ? \""
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in text1, collapse \" n ' t\" to the \"n't\" ending surrounded by spaces)\n",
    "text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I do n't know who Kara 's 10 new friend ( s )  are ;   -  -  is one of them  ' Mr .  / Mrs .  Toad '  ? \""
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in text2, collapse \" ' s \" to the \"'s\" ending, surrounded by spaces\n",
    "text3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I do n't know who Kara 's 10 new friend ( s ) are ; - - is one of them ' Mr . / Mrs . Toad ' ? \""
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in text3, collapse all strings of multiple spaces to one space\n",
    "text4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i do n't know who kara 's 10 new friend ( s ) are ; - - is one of them ' mr . / mrs . toad ' ? \""
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lower case text4 \n",
    "text5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'know',\n",
       " 'who',\n",
       " 'kara',\n",
       " \"'s\",\n",
       " '10',\n",
       " 'new',\n",
       " 'friend',\n",
       " '(',\n",
       " 's',\n",
       " ')',\n",
       " 'are',\n",
       " ';',\n",
       " '-',\n",
       " '-',\n",
       " 'is',\n",
       " 'one',\n",
       " 'of',\n",
       " 'them',\n",
       " \"'\",\n",
       " 'mr',\n",
       " '.',\n",
       " '/',\n",
       " 'mrs',\n",
       " '.',\n",
       " 'toad',\n",
       " \"'\",\n",
       " '?']"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split text5 on blank space to create a list of tokens, the final result\n",
    "text6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now try the tokenizer on a list of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['All this happened, more or less.',\n",
    "             'The war parts, anyway, are pretty much true.',\n",
    "             \"One guy I knew really was shot for taking a teapot that wasn't his.\",\n",
    "             'Another guy I knew really did threaten to have his personal enemies killed by hired gunmen after the war.',\n",
    "             'And so on.',\n",
    "             \"I've changed all their names.\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  the `map` function applies the simple_toks function to the input list of sentences, producing an object of the `map` class, which can be acted upon by list() to produce a `list` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'map'>\n"
     ]
    }
   ],
   "source": [
    "print(type(map(simple_toks, sentences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(list(map(simple_toks, sentences))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = list(map(simple_toks, sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['all', 'this', 'happened', ',', 'more', 'or', 'less', '.'],\n",
       " ['the',\n",
       "  'war',\n",
       "  'parts',\n",
       "  ',',\n",
       "  'anyway',\n",
       "  ',',\n",
       "  'are',\n",
       "  'pretty',\n",
       "  'much',\n",
       "  'true',\n",
       "  '.'],\n",
       " ['one',\n",
       "  'guy',\n",
       "  'i',\n",
       "  'knew',\n",
       "  'really',\n",
       "  'was',\n",
       "  'shot',\n",
       "  'for',\n",
       "  'taking',\n",
       "  'a',\n",
       "  'teapot',\n",
       "  'that',\n",
       "  'was',\n",
       "  \"n't\",\n",
       "  'his',\n",
       "  '.'],\n",
       " ['another',\n",
       "  'guy',\n",
       "  'i',\n",
       "  'knew',\n",
       "  'really',\n",
       "  'did',\n",
       "  'threaten',\n",
       "  'to',\n",
       "  'have',\n",
       "  'his',\n",
       "  'personal',\n",
       "  'enemies',\n",
       "  'killed',\n",
       "  'by',\n",
       "  'hired',\n",
       "  'gunmen',\n",
       "  'after',\n",
       "  'the',\n",
       "  'war',\n",
       "  '.'],\n",
       " ['and', 'so', 'on', '.'],\n",
       " ['i', \"'\", 've', 'changed', 'all', 'their', 'names', '.']]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our tokens, the next step is to convert them to integer ids.  We will also need to get our vocabulary list, and have a way to convert between the words and their associated ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD = 0; SOS = 1\n",
    "\n",
    "def toks2ids(sentences):\n",
    "    voc_cnt = collections.Counter(t for sent in sentences for t in sent)\n",
    "    vocab = sorted(voc_cnt, key=voc_cnt.get, reverse=True)\n",
    "    vocab.insert(PAD, \"<PAD>\")\n",
    "    vocab.insert(SOS, \"<SOS>\")\n",
    "    w2id = {w:i for i,w in enumerate(vocab)}\n",
    "    ids = [[w2id[t] for t in sent] for sent in sentences]\n",
    "    return ids, vocab, w2id, voc_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids, vocab, w2id, voc_cnt = toks2ids(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 13, 14, 3, 15, 16, 17, 2],\n",
       " [6, 7, 18, 3, 19, 3, 20, 21, 22, 23, 2],\n",
       " [24, 8, 4, 9, 10, 11, 25, 26, 27, 28, 29, 30, 11, 31, 12, 2],\n",
       " [32, 8, 4, 9, 10, 33, 34, 35, 36, 12, 37, 38, 39, 40, 41, 42, 43, 6, 7, 2],\n",
       " [44, 45, 46, 2],\n",
       " [4, 47, 48, 49, 5, 50, 51, 2]]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<PAD>',\n",
       " '<SOS>',\n",
       " '.',\n",
       " ',',\n",
       " 'i',\n",
       " 'all',\n",
       " 'the',\n",
       " 'war',\n",
       " 'guy',\n",
       " 'knew',\n",
       " 'really',\n",
       " 'was',\n",
       " 'his',\n",
       " 'this',\n",
       " 'happened',\n",
       " 'more',\n",
       " 'or',\n",
       " 'less',\n",
       " 'parts',\n",
       " 'anyway',\n",
       " 'are',\n",
       " 'pretty',\n",
       " 'much',\n",
       " 'true',\n",
       " 'one',\n",
       " 'shot',\n",
       " 'for',\n",
       " 'taking',\n",
       " 'a',\n",
       " 'teapot',\n",
       " 'that',\n",
       " \"n't\",\n",
       " 'another',\n",
       " 'did',\n",
       " 'threaten',\n",
       " 'to',\n",
       " 'have',\n",
       " 'personal',\n",
       " 'enemies',\n",
       " 'killed',\n",
       " 'by',\n",
       " 'hired',\n",
       " 'gunmen',\n",
       " 'after',\n",
       " 'and',\n",
       " 'so',\n",
       " 'on',\n",
       " \"'\",\n",
       " 've',\n",
       " 'changed',\n",
       " 'their',\n",
       " 'names']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: what could be another name of the `vocab` variable above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<PAD>': 0,\n",
       " '<SOS>': 1,\n",
       " '.': 2,\n",
       " ',': 3,\n",
       " 'i': 4,\n",
       " 'all': 5,\n",
       " 'the': 6,\n",
       " 'war': 7,\n",
       " 'guy': 8,\n",
       " 'knew': 9,\n",
       " 'really': 10,\n",
       " 'was': 11,\n",
       " 'his': 12,\n",
       " 'this': 13,\n",
       " 'happened': 14,\n",
       " 'more': 15,\n",
       " 'or': 16,\n",
       " 'less': 17,\n",
       " 'parts': 18,\n",
       " 'anyway': 19,\n",
       " 'are': 20,\n",
       " 'pretty': 21,\n",
       " 'much': 22,\n",
       " 'true': 23,\n",
       " 'one': 24,\n",
       " 'shot': 25,\n",
       " 'for': 26,\n",
       " 'taking': 27,\n",
       " 'a': 28,\n",
       " 'teapot': 29,\n",
       " 'that': 30,\n",
       " \"n't\": 31,\n",
       " 'another': 32,\n",
       " 'did': 33,\n",
       " 'threaten': 34,\n",
       " 'to': 35,\n",
       " 'have': 36,\n",
       " 'personal': 37,\n",
       " 'enemies': 38,\n",
       " 'killed': 39,\n",
       " 'by': 40,\n",
       " 'hired': 41,\n",
       " 'gunmen': 42,\n",
       " 'after': 43,\n",
       " 'and': 44,\n",
       " 'so': 45,\n",
       " 'on': 46,\n",
       " \"'\": 47,\n",
       " 've': 48,\n",
       " 'changed': 49,\n",
       " 'their': 50,\n",
       " 'names': 51}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What are the uses of RegEx?\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Find / Search\n",
    "2. Find & Replace\n",
    "3. Cleaning data by removing unwanted characters\n",
    "4. Processing text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Don't forgot about Python's `str` methods\n",
    "-----\n",
    "\n",
    "`str.<tab>`\n",
    "    \n",
    "str.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "str?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12,', '14,', '22,', '17,', '31']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '12, 14, 22, 17, 31'\n",
    "dd = text.split(' ')\n",
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getnewargs__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__mod__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rmod__',\n",
       " '__rmul__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'capitalize',\n",
       " 'casefold',\n",
       " 'center',\n",
       " 'count',\n",
       " 'encode',\n",
       " 'endswith',\n",
       " 'expandtabs',\n",
       " 'find',\n",
       " 'format',\n",
       " 'format_map',\n",
       " 'index',\n",
       " 'isalnum',\n",
       " 'isalpha',\n",
       " 'isascii',\n",
       " 'isdecimal',\n",
       " 'isdigit',\n",
       " 'isidentifier',\n",
       " 'islower',\n",
       " 'isnumeric',\n",
       " 'isprintable',\n",
       " 'isspace',\n",
       " 'istitle',\n",
       " 'isupper',\n",
       " 'join',\n",
       " 'ljust',\n",
       " 'lower',\n",
       " 'lstrip',\n",
       " 'maketrans',\n",
       " 'partition',\n",
       " 'replace',\n",
       " 'rfind',\n",
       " 'rindex',\n",
       " 'rjust',\n",
       " 'rpartition',\n",
       " 'rsplit',\n",
       " 'rstrip',\n",
       " 'split',\n",
       " 'splitlines',\n",
       " 'startswith',\n",
       " 'strip',\n",
       " 'swapcase',\n",
       " 'title',\n",
       " 'translate',\n",
       " 'upper',\n",
       " 'zfill']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Regex vs. String methods\n",
    "-----\n",
    "\n",
    "1. String methods are easier to understand.\n",
    "1. String methods express the intent more clearly. \n",
    "\n",
    "-----\n",
    "\n",
    "1. Regex handle much broader use cases.\n",
    "1. Regex can be language independent.\n",
    "1. Regex can be faster at scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What about unicode?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'üòäüé¶ üòäüçï'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = \"üòíüé¶ ü§¢üçï\"\n",
    "\n",
    "re_frown = re.compile(r\"üòí|ü§¢\")\n",
    "re_frown.sub(r\"üòä\", message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regex Errors:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__False positives__ (Type I): Matching strings that we should __not__ have\n",
    "matched\n",
    "\n",
    "__False negatives__ (Type II): __Not__ matching strings that we should have matched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Reducing the error rate for a task often involves two antagonistic efforts:\n",
    "\n",
    "1. Minimizing false positives\n",
    "2. Minimizing false negatives\n",
    "\n",
    "**Important to have tests for both!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In a perfect world, you would be able to minimize both but in reality you often have to trade one for the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Useful Tools:\n",
    "----\n",
    "- [Regex cheatsheet](http://www.cheatography.com/davechild/cheat-sheets/regular-expressions/)\n",
    "- [regexr.com](http://regexr.com/) Realtime regex engine\n",
    "- [pyregex.com](https://pythex.org/) Realtime Python regex engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Summary\n",
    "----\n",
    "\n",
    "1. We use regex as a metalanguage to find string patterns in blocks of text\n",
    "1. `r\"\"` are your IRL friends for Python regex\n",
    "1. We are just doing binary classification so use the same performance metrics\n",
    "1. You'll make a lot of mistakes in regex üò©. \n",
    "    - False Positive: Thinking you are right but you are wrong\n",
    "    - False Negative: Missing something"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/face_tat.png\" width=\"700\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://imgs.xkcd.com/comics/perl_problems.png\" width=\"700\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://imgs.xkcd.com/comics/regex_golf.png\" width=\"700\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Regex Terms\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- __target string__:\tThis term describes the string that we will be searching, that is, the string in which we want to find our match or search pattern.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- __search expression__: The pattern we use to find what we want. Most commonly called the regular expression. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- __literal__:\tA literal is any character we use in a search or matching expression, for example, to find 'ind' in 'windows' the 'ind' is a literal string - each character plays a part in the search, it is literally the string we want to find."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- __metacharacter__: A metacharacter is one or more special characters that have a unique meaning and are NOT used as literals in the search expression. For example \".\" means any character.\n",
    "\n",
    "Metacharacters are the special sauce of regex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- __escape sequence__:\tAn escape sequence is a way of indicating that we want to use a metacharacters as a literal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In a regular expression an escape sequence involves placing the metacharacter \\ (backslash) in front of the metacharacter that we want to use as a literal. \n",
    "\n",
    "`'\\.'` means find literal period character (not match any character)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regex Workflow\n",
    "---\n",
    "1. Create pattern in Plain English\n",
    "2. Map to regex language\n",
    "3. Make sure results are correct:\n",
    "    - All Positives: Captures all examples of pattern\n",
    "    - No Negatives: Everything captured is from the pattern\n",
    "4. Don't over-engineer your regex. \n",
    "    - Your goal is to Get Stuff Done, not write the best regex in the world\n",
    "    - Filtering before and after are okay."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
